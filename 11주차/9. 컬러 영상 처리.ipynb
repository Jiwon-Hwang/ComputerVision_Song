{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컬러 영상 처리\n",
    "* 컬러 영상 다루기\n",
    "* 컬러 영상 처리 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컬러 영상 다루기\n",
    "* OpenCV에서 각 색상 성분 값은 uchar(unsigned char, 1byte) 자료형을 사용해 표현\n",
    "> 파이썬의 경우 **uint8** 리스트 (**numpy array!**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 컬러 영상의 픽셀 값 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356, 493, 3)\n",
      "uint8\n",
      "<class 'numpy.ndarray'>\n",
      "The pixel value [B, G, R] at (0, 0) is [47 88 50]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def color_op():\n",
    "    src = cv2.imread('color_image_processing/butterfly.jpg', cv2.IMREAD_COLOR)\n",
    "    \n",
    "    print(src.shape) # (row, col, channel)\n",
    "    print(src.dtype) # uint8\n",
    "    print(type(src)) # np.ndarray\n",
    "    \n",
    "    # b, g, r = src[0, 0] !!(각각 3채널)\n",
    "    print('The pixel value [B, G, R] at (0, 0) is', src[0, 0])\n",
    "    \n",
    "color_op()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 컬러 영상 반전 (inverse)\n",
    "* B, G, R 각각에서 255씩 빼는 연산\n",
    "* np.zeros로 초기화 & src.shape, src.dtype 그대로 가져와서 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_inverse():\n",
    "    src = cv2.imread('color_image_processing/butterfly.jpg', cv2.IMREAD_COLOR)\n",
    "    \n",
    "    dst = np.zeros(src.shape, src.dtype) # np.zeros(size, dtype)\n",
    "    \n",
    "    for j in range(src.shape[0]): # row\n",
    "        for i in range(src.shape[1]): # col\n",
    "            p1 = src[j, i] # [b, g, r]\n",
    "            p2 = dst[j, i] # [b, g, r]\n",
    "            \n",
    "            p2[0] = 255 - p1[0] # B\n",
    "            p2[1] = 255 - p1[1] # G\n",
    "            p2[2] = 255 - p1[2] # R\n",
    "            \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "color_inverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](inverse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 색 공간 변환\n",
    "* BGR -> HSV, HSL, YCrCb, YUV\n",
    "* **[ 변환 목적 : 색상 값은 그대로 두고, 밝기, 명도, 채도 등을 바꾸고 싶을 때! ]** \n",
    "* **cv2.cvtColor()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BGR2GRAY와 GRAY2BGR\n",
    "* 컬러영상을 그레이스케일로 변환하는 이유? ==> for **연산 속도 & 메모리 사용량 줄이기**\n",
    "    * 컬러 영상은 크레이스케일 영상보다 3배 많은 메모리와 연산 시간 필요!  \n",
    "    * BGR 3채널 -> 그레이스케일 1채널 변환 공식\n",
    "    * **Y = 0.299R + 0.587G + 0.114B** (Y : 해당 픽셀의 그레이스케일 성분 크기)\n",
    "    * 결과영상 타입 : CV_8UC1\n",
    "      \n",
    "        \n",
    "* 그레이스케일 -> 컬러 영상 \n",
    "    * **R = G = B = Y** (Y값을 R, G, B에 각각 대입)\n",
    "    * 결과영상 타입 : CV_8UC3\n",
    "    > 주로 그레이스케일 영상 위에 색깔이 있는 선이나 글씨를 나타내기 전 미리 변환!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BGR2HSV와 HSV2BGR\n",
    "* H(Hue, 색상), S(Saturation, 채도), V(Value, 명도)\n",
    "    * 색상 : 색의 종류 (B, G, R) ==> 각도가 증가할수록 빨강->초록->파랑 (0~179)\n",
    "    * 채도 : 색의 순도 (탁하고 쨍함) ==> 원의 중심에서 최솟값 (0~255)\n",
    "    * 명도 : 빛의 세기 (어둡고 밝음) ==> 원뿔 아래 꼭지점에서 최솟값 (0~255)\n",
    "![](HSV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BGR2YCrCb와 YCrCb2BGR\n",
    "* YCrCb : 영상을 **그레이스케일 정보(Y)와 색상 정보(Cr, Cb)로 분리**하여 처리할 때 유용\n",
    "    * Y(Luminance, 밝기 또는 휘도) ==> Y = B+G+R\n",
    "    * Cr, Cb(Chrominance, 색상 또는 색차) ==> 밝기 정보는 포함 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 그레이스케일 변환\n",
    "3채널 BGR 컬러 영상 -> 그레이스케일로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_grayscale():\n",
    "    src = cv2.imread('color_image_processing/butterfly.jpg', cv2.IMREAD_COLOR)\n",
    "    \n",
    "    dst = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "color_grayscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 색상 채널 나누기\n",
    "* 컬러 영상을 다루다 보면 빨간색 성분만 이용하거나, HSV 색 공간으로 변환 후 H 성분만 이용할 때 채널 분리\n",
    "* **cv2.split()** : 3채널 -> 1채널 여러 개 \n",
    "* **cv2.merge()** : 1채널 여러 개 -> 3채널"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 색상 채널 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "def color_split():\n",
    "    src = cv2.imread('color_image_processing/candies.png', cv2.IMREAD_COLOR)\n",
    "    \n",
    "    # b_plane, g_plane, r_plane = cv2.split(src)\n",
    "    bgr_planes = cv2.split(src)\n",
    "    print(type(bgr_planes), type(bgr_planes[0])) # 2차원 list 안에 np.array\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('B_plane', bgr_planes[0]) # Blue 부분만 255에 가까운 값인 흰색으로 나옴\n",
    "    cv2.imshow('G_plane', bgr_planes[1]) # G 부분만 흰색\n",
    "    cv2.imshow('R_plane', bgr_planes[2]) # R 부분만 흰색\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "color_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](rgb_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컬러 영상 처리 기법\n",
    "## 컬러 히스토그램 평활화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **cv2.equlizeHist(src_gray)** : 히스토그램 평활화 수행 함수\n",
    "    * **그레이스케일 영상만** input으로 가능\n",
    "    * R, G, B 각 채널로 나누고, 채널별로 히스토그램 평활화 진행 후 합칠 수도 있긴 함\n",
    "    * But, 원본과는 다른 색상의 결과 영상 발생..  \n",
    "      \n",
    "      \n",
    "* 색감은 변경하지 않고, **명암비**를 높이려면? ==> 영상의 **밝기 정보만** 사용해야 함\n",
    "    * **밝기 정보에 대해서만 히스토그램 평활화**\n",
    "    * ex. BGR -> YCrCb 색 공간으로 변환 후, **Y 성분에 대해서만 히스토그램 평활화**\n",
    "    * 최종적으로 **변경된 Y 채널 + Cr, Cb 채널 합치기**\n",
    "> cf. **Y 채널 : 그레이스케일 정보 (밝기 정보)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 컬러 히스토그램 평활화\n",
    "* cf. 히스토그램 평활화 : 명암 분포를 넓게 해서, 어두운 부분은 더 어둡게, 밝은 부분은 더 밝게 명암 대비를 강하게!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread('color_image_processing/pepper.bmp', cv2.IMREAD_COLOR)\n",
    "\n",
    "src_ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCrCb) # BGR -> YCrCb\n",
    "\n",
    "ycrcb_planes = cv2.split(src_ycrcb) \n",
    "print(len(ycrcb_planes)) # Y, Cr, Cb ==> 3 채널\n",
    "\n",
    "ycrcb_planes[0] = cv2.equalizeHist(ycrcb_planes[0]) # Y 채널 업데이트\n",
    "\n",
    "dst_ycrcb = cv2.merge(ycrcb_planes)\n",
    "\n",
    "dst = cv2.cvtColor(dst_ycrcb, cv2.COLOR_YCrCb2BGR) # YCrCb -> BGR\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pepper_hist.png)\n",
    "색감은 그대로 유지한 채, 명암비가 높아짐!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 색상 범위 지정에 의한 영역 분할\n",
    "* ex. 빨간 부분만 남기고 나머지는 다 흑백 처리 등\n",
    "* RGB 색 공간보다 **HSV 등의 색상(H) 정보가 따로 설정되어 있는 색 공간** 사용하는게 유리! \n",
    "    * ex. HSV 공간에서 H = 60 정도 ==> 녹색! (***따라서 H값이 60에 가까운지 조사***)\n",
    "    * OpenCV에서는 H값 범위 : 0 ~ 179 사이 값 사용 (0 : 빨간색)\n",
    "   \n",
    "  \n",
    "> **cv2.inRange(src, lowerb, upperb)** : src의 픽셀 값이 특정 범위 안에 있는지 확인 (**마스크 구하기**)  \n",
    "* if 범위 내 포함 ==> **흰색** 마스크 영상\n",
    "* if 범위 내 미포함 ==> **검은색** 마스크 영상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](inRange.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 색상 범위 지정에 의한 영역 분할\n",
    "두 개의 트랙바를 붙여서 **HSV 색 공간**에서 **색상(H)의 하한 값(lower_hue)과 상한 값(upper_hue)**을 설정할 수 있도록 함  \n",
    "> 색상(H)의 범위(0~360도 -> 0~179도)를 지정할 것이므로, HSV 색 공간 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_hue_changed(_=None):\n",
    "    lower_hue = cv2.getTrackbarPos('Lower Hue', 'mask') # 트랙바의 현재 위치 get\n",
    "    upper_hue = cv2.getTrackbarPos('Upper Hue', 'mask')\n",
    "    \n",
    "    # (H, S, V)에서 H 값의 하한, 상한 값 범위 변동 (트랙바에 따라)\n",
    "    lowerb = (lower_hue, 100, 0) # H : lower_hue ~ upper_hue / S : 100~255 / V : 전체\n",
    "    upperb = (upper_hue, 255, 255)\n",
    "    mask = cv2.inRange(src_hsv, lowerb, upperb)\n",
    "    \n",
    "    cv2.imshow('mask', mask)\n",
    "    \n",
    "def main():\n",
    "    global src_hsv # 전역 변수 선언만 (정의 x)\n",
    "    \n",
    "    src = cv2.imread('color_image_processing/candies.png', cv2.IMREAD_COLOR)\n",
    "    \n",
    "    src_hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    \n",
    "    cv2.namedWindow('mask') # 윈도우에 창 이름 설정\n",
    "    # cv2.createTrackbar(트랙바 이름, 트랙바 생성할 창이름, 시작위치, 최대위치, 콜백~)\n",
    "    cv2.createTrackbar('Lower Hue', 'mask', 40, 179, on_hue_changed) # 트랙바 생성\n",
    "    cv2.createTrackbar('Upper Hue', 'mask', 80, 179, on_hue_changed)\n",
    "    on_hue_changed(0) # 콜백 함수 종료!\n",
    "    \n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R\n",
    "![](R.png)\n",
    "#### G\n",
    "![](G.png)\n",
    "#### B\n",
    "![](B.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 히스토그램 역투영 (histogram backprojection)\n",
    "* 위의 방법 (BGR -> HSV -> inRange) : 원색에 가까운 색상을 찾는데는 효과적\n",
    "* But, 사람의 피부 등과 같이 수치적으로 지정하기 어려운 경우엔 적합 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 히스토그램 역투영 : **기준 영상으로부터 찾고자 하는 객체의 컬러 히스토그램을 미리 구하고, 입력 영상에서 이 히스토그램에 부합하는 영역을 찾는 방식**\n",
    "* **cv2.calcBackProject([src_ycrcb], channels, hist, ranges, scale)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 히스토그램 역투영\n",
    "기준 영상(ref)으로부터 피부색 영역에 대한 히스토그램(**CrCb 2차원 hist**) 추출 후, 이 히스토그램 정보를 이용해 입력 영상에서 피부색 영역 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = cv2.imread('color_image_processing/ref.png', cv2.IMREAD_COLOR)\n",
    "mask = cv2.imread('color_image_processing/mask.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 기준 영상 ref_ycrcb에서 CrCb 2차원 히스토그램 구하고, hist에 저장\n",
    "ref_ycrcb = cv2.cvtColor(ref, cv2.COLOR_BGR2YCrCb) \n",
    "\n",
    "channels = [1, 2] # 1, 2번째 채널 (Cr채널, Cb 채널)\n",
    "cr_bins = 128 # Cr 채널의 빈 개수 (히스토그램 크기) ==> 0~255를 128개로 나누겠다!\n",
    "cb_bins = 128 # Cb 채널의 빈 개수 (히스토그램 크기) ==> 즉, 한 빈당 2정도 크기\n",
    "histSize = [cr_bins, cb_bins] # 히스토그램 크기 : 128 x 128\n",
    "cr_range = [0, 256]\n",
    "cb_range = [0, 256]\n",
    "ranges = cr_range + cb_range\n",
    "\n",
    "# YCrCb공간에서 CrCb채널에서만, 마스크에 해당하는 부분의 히스토그램만 구하기\n",
    "hist = cv2.calcHist([ref_ycrcb], channels, mask, histSize, ranges) # 히스토그램 get\n",
    "\n",
    "# Apply histogram backprojection to an input image\n",
    "\n",
    "src = cv2.imread('color_image_processing/kids.png', cv2.IMREAD_COLOR)\n",
    "src_ycrcb = cv2.cvtColor(src, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "# backproj : 히스토그램 역투영을 통해 구한 피부색 영역 영상! (CV_8UC1 -> imshow 가능)\n",
    "backproj = cv2.calcBackProject([src_ycrcb], channels, hist, ranges, 1) # scale = 1배\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('backproj', backproj)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('ref', ref)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ref,mask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](calcBackProject.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* backproj에서 흰색 부분 : 입력 영상의 픽셀 값이, **지정한 히스토그램에서 높은 빈도수로 표현됨**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
