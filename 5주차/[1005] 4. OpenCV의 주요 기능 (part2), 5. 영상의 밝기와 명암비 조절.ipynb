{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 마스크 영상 2\n",
    "* 마스크 영상에 의해 지정된 일부 영역만 복사하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비행기 사진에서 마스킹 영역만 가져와서 필드 영상에 복사하기 (덮어씌우기)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def mask_copyTo():\n",
    "    src = cv2.imread('airplane.bmp', cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread('mask_plane.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    dst = cv2.imread('field.bmp', cv2.IMREAD_COLOR)\n",
    "    \n",
    "    if src is None or mask is None or dst is None:\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "    \n",
    "    dst[mask > 0] = src[mask > 0] # 마스크에서 흰색 영역만 복사됨\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imwrite('result.png', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "mask_copyTo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산 시간 측정\n",
    "* OpenCV 라이브러리를 이용하면 운영체제에 상관 없이 연산 시간 측정 가능\n",
    "* tm = **cv2.TickMeter()** 클래스\n",
    "* tm.start()\n",
    "* tm.stop()\n",
    "* **tm.getTimeMilli()** : ms 단위로 시간 측정 (계산 시간 가져오기)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) 연산 시간 측정\n",
    "* For문을 활용해 영상을 직접 한 픽셀씩 반전시키고, 이때 소요되는 시간을 측정하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image inverse implementation took 586.288 ms.\n"
     ]
    }
   ],
   "source": [
    "# 1. for문 사용시 연산 시간 측정\n",
    "\n",
    "def time_inverse():\n",
    "    src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    dst = np.empty(src.shape, dtype=src.dtype) # 초기화 없이 배열 생성\n",
    "    \n",
    "    tm = cv2.TickMeter()\n",
    "    tm.start()\n",
    "    \n",
    "    for y in range(src.shape[0]): # row\n",
    "        for x in range(src.shape[1]): # col\n",
    "            dst[y, x] = 255 - src[y, x]\n",
    "            \n",
    "    tm.stop()\n",
    "    print('Image inverse implementation took %4.3f ms.'% tm.getTimeMilli())\n",
    "\n",
    "time_inverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image inverse implementation took 0.387 ms.\n"
     ]
    }
   ],
   "source": [
    "# 2. ~ 연산자 (numpy 벡터화 연산) 사용시 연산 시간 측정 ==> 훨씬 빠르다!\n",
    "\n",
    "def time_inverse2():\n",
    "    src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    dst = np.empty(src.shape, dtype=src.dtype) # 초기화 없이 배열 생성\n",
    "    \n",
    "    tm = cv2.TickMeter()\n",
    "    tm.start()\n",
    "    \n",
    "    dst = ~src # 벡터화 연산 (numpy 연산)\n",
    "            \n",
    "    tm.stop()\n",
    "    print('Image inverse implementation took %4.3f ms.'% tm.getTimeMilli())\n",
    "\n",
    "time_inverse2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  22 135]\n",
      " [184 249 127]\n",
      " [  0   0  96]]\n"
     ]
    }
   ],
   "source": [
    "# cf. np.empty : 특정 값으로 초기화해주지 않아 빠르지만\n",
    "# 임의의 값들이 들어가있어서 추후 값을 직접 재할당 해주어야 한다!\n",
    "\n",
    "test = np.empty((3, 3), dtype=np.uint8)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유용한 OpenCV, NumPy 함수 사용법\n",
    "* **np.sum()** : 행렬의 전체 원소 합\n",
    "* **np.mean()** : 행렬의 전체 원소 평균 / 마스크 연산 지원 (특정 영역의 평균)\n",
    "    * 둘 다 4채널 이하의 행렬에 대해서만 동작 (RGBA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **cv2.minMaxLoc()** : 행렬의 **최솟값, 최댓값**을 찾는 함수. 해당 값의 **좌표**도 함께 알수있음 (min, max, location)\n",
    "    * 파이썬에서는 **tuple** 형태로 return\n",
    "    * **grayscale만** 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **cv2.normalize()** : 행렬의 norm값을 정규화하거나 원소 값 범위를 특정 범위로 정규화할 때 사용 (**0 ~ 1 사이 값**으로) / **\"norm_type\"** 인자에 따라 동작 결정\n",
    "     \n",
    "    * norm_type = **NORM_IMF** : L-infinity norm (**최대 절댓값**을 반환)\n",
    "        * ex) x = [-6, 4, 2] ==> norm : 6\n",
    "          \n",
    "    * norm_type = **NORM_L1** : L1 norm (Manhattan Distance, **두 점 사이 직각 거리**. 즉, **각각의 차의 절댓값의 합**)\n",
    "        * ex) (0, 0) ~ (3, 4) ==> norm : |3| + |4| = 7\n",
    "          \n",
    "    * norm_type = **NORM_L2** : L2 norm (Euclidean Distance, **각각의 차의 제곱 합의 루트**) \n",
    "        * ex) (0, 0) ~ (3, 4) ==> norm : 5\n",
    "      > 만약 norm_type = **NORM_MINMAX** 이면, src 행렬의 최솟값이 **alpha**, 최댓값이 **beta**가 되도록 원소값 크기 조절 (대부분 이렇게 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **round()** : 파이썬 **내장** 함수. 실수를 정수로 변환 (**반올림**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) np.sum, np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 28890183\n",
      "mean: 110\n"
     ]
    }
   ],
   "source": [
    "def useful_func():\n",
    "    img = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None :\n",
    "        print('Image load failed!')\n",
    "        return\n",
    "    \n",
    "    sum_img = np.sum(img)\n",
    "    mean_img = np.mean(img, dtype = np.int32)\n",
    "    print('sum:', sum_img)\n",
    "    print('mean:', mean_img)\n",
    "\n",
    "useful_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_mask: 109\n"
     ]
    }
   ],
   "source": [
    "# cf. np.mean()과 마스크 연산 ==> 특정 마스크 영역의 원소 평균 구하기\n",
    "\n",
    "def mean_mask():\n",
    "    img = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.imread('mask_smile.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    mean_mask_img = np.mean(img[mask > 0], dtype = np.int32) # 마스크 흰색 영역 평균\n",
    "    print('mean_mask:', mean_mask_img)\n",
    "\n",
    "mean_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) cv2.minMaxLoc()\n",
    "* 단, img는 **grayscale만** 가능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22.0, 239.0, (508, 71), (117, 272))\n",
      "minVal is 22.0 at (508, 71)\n",
      "maxVal is 239.0 at (117, 272)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE) # Grayscale만 됨!!\n",
    "minVal, maxVal, minPos, maxPos = cv2.minMaxLoc(img)\n",
    "print(cv2.minMaxLoc(img))\n",
    "print('minVal is', minVal, 'at', minPos)\n",
    "print('maxVal is', maxVal, 'at', maxPos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) cv2.normalize()\n",
    "* -1에서 1 사이의 실수로 구성된 1 x 5 행렬을 0부터 255 사이의 정수 행렬로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src: [[-1.  -0.5  0.   0.5  1. ]]\n",
      "dst: [[  0  64 128 191 255]]\n"
     ]
    }
   ],
   "source": [
    "# 최솟값 : 0, 최댓값 : 255 로 normalize\n",
    "src = np.array([[-1, -0.5, 0, 0.5, 1]], dtype = np.float32)\n",
    "dst = cv2.normalize(src, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U) # uint8(8bit)행렬\n",
    "print('src:', src)\n",
    "print('dst:', dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (실습) round()\n",
    "정확히 **0.5**인 경우에는 **짝/홀수**에 따라서 다름!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(round(2.5)) # 짝수.5 ==> 내림\n",
    "print(round(2.51))\n",
    "print(round(3.499))\n",
    "print(round(3.5)) # 홀수.5 ==> 올림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 5. 영상의 밝기와 명암비 조절\n",
    "* 영상의 밝기 조절 (cv2.add(), cv2.subtract())\n",
    "* 영상의 명암비 조절 (cv2.multiply())\n",
    "* 히스토그램 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상의 밝기 조절\n",
    "* cv2.cvtColor(srt, dst, 컬러변환코드)\n",
    "* saturate() : 포화 연산 (범위를 벗어나는 값 가질 경우 자료형의 최대 or 최대값으로 설정)\n",
    "    * if) uchar 자료형 ==> 0 ~ 255\n",
    "* 실제로 영상의 밝기 조절 시 **포화연산** 고려해야 함!\n",
    "> **cv2.add()** & **cv2.subtract()** 함수 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.add(), cv2.subtract() ==> 자동으로 포화연산 수행\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def brightness1():\n",
    "    src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    dst1 = cv2.add(src, 100) # 덧셈 연산\n",
    "    dst2 = cv2.subtract(src, 100) # 뺄셈 연산\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst_add', dst1)\n",
    "    cv2.imshow('dst_subtract', dst2)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "brightness1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상의 밝기 조절 직접 +, -로 구현하기 ==> 포화연산 적용 안되어서 찢어지는 부분 발생\n",
    "\n",
    "def brightness2():\n",
    "    src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    dst = np.empty(src.shape, src.dtype)\n",
    "    \n",
    "    for y in range(src.shape[0]):\n",
    "        for x in range(src.shape[1]):\n",
    "            dst[y, x] = src[y, x] + 100 # 255 넘는 값(overflow) : 0부터로 처리\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "brightness2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이중 for문을 수정하여 정상적인 밝기 조절 구현 ==> 3항연산자로 0~255 넘는 값 처리\n",
    "\n",
    "def saturated(value):\n",
    "    if value > 255:\n",
    "        value = 255\n",
    "    elif value < 0:\n",
    "        value = 0\n",
    "    \n",
    "    return value\n",
    "\n",
    "def brightness3():\n",
    "    src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    dst = np.empty(src.shape, src.dtype)\n",
    "    \n",
    "    for y in range(src.shape[0]):\n",
    "        for x in range(src.shape[1]):\n",
    "            dst[y, x] = saturated(src[y, x] + 100) # 모든 픽셀마다 포화연산 함수로\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "brightness3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트랙바를 이용한 영상의 밝기 조절\n",
    "* 매번 소스 코드 수정과 빌드 필요 없이, add() 함수와 트랙바를 통해 곧바로 결과 확인 가능\n",
    "* cv2.createTrackbar(트랙바 이름, 트랙바 생성할 창 이름, 시작 위치, 최대 위치, 콜백함수명)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 영상 + 0~100 사이 값 조절\n",
    "def brightness4():\n",
    "    src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # 트랙바 콜백함수\n",
    "    def update(pos): \n",
    "        dst = cv2.add(src, pos) # src + pos(트랙바 값)\n",
    "        cv2.imshow('dst', dst)\n",
    "    \n",
    "    cv2.namedWindow('dst')\n",
    "    cv2.createTrackbar('Brightness', 'dst', 0, 100, update) # update : 콜백함수\n",
    "    update(0) # 처음에 보여줄 이미지 (디폴트 pos = 0)\n",
    "    \n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "brightness4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영상의 명암비 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본적인 명암비 조절\n",
    "* 명암비 == **명암 대비** == 콘트라스트 (**contrast**)\n",
    "* 밝은 영역과 어두운 영역 사이에 드러나는 밝기 차이의 강도\n",
    "* \"**명암비가 낮다**\" == 전반적으로 어둡거나 전반적으로 밝은 픽셀로만 구성된 경우\n",
    "    * 객체 간 구분이 잘 되지 않아서 전반적으로 **흐림**\n",
    "* \"**명암비가 높다**\" == 밝고 어두운 영역이 **골고루** 섞여 있다\n",
    "    * 사물의 구분이 잘 되며 **선명함**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본적인 명암비 조절 방법\n",
    "* **cv2.multiply()** 함수 이용 (실전에서는 잘 안씀)\n",
    "* dst = saturated(s * src)에서,\n",
    "    * **s = 0.5** : 0~255 -> 0~128 이므로 밝기 차이(기울기)가 줄어듦 (**명암비 작아짐**)\n",
    "    * **s = 2** : 0~255 -> 원본의 128 밝기부분이 255가 되어 큰 밝기로 변함 (**명암비 커짐**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.multiply() ==> 모든 픽셀값에 2배하여 명암대비 크게 하기\n",
    "\n",
    "def contrast1():\n",
    "    src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    s = 2.0\n",
    "    dst = cv2.multiply(src, s)\n",
    "    \n",
    "    cv2.imshow('src', src)\n",
    "    cv2.imshow('dst', dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "contrast1() \n",
    "\n",
    "# 전체적으로 포화되어 흰색 영역이 너무 많아서 윤곽 구분 더 어려워짐\n",
    "# 실전에서는 곱셈을 이용해 명암비 조절 방식 잘 안씀!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
